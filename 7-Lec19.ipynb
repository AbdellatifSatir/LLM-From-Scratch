{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a GPT Model from Scratch to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 small config\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\" : 50257,\n",
    "    \"context_length\" : 1024,\n",
    "    \"emb_dim\" : 768,\n",
    "    \"n_heads\" : 12,\n",
    "    \"n_layers\" : 12,\n",
    "    \"drop_rate\" : 0.1,\n",
    "    \"qkv_bias\" : False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT Architecture Part 1 : DUMMY GPT Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        # Use a placeholder for LayerNorm\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformeBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "\n",
    "        self.final_norm = DummyLayerNorm(cfg['emb_dim'])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg['emb_dim'], cfg['vocab_size'], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "\n",
    "        X = tok_embeds + pos_embeds\n",
    "        X = self.drop_emb(X)\n",
    "        X = self.trf_blocks(X) # transformer blocks\n",
    "        X = self.final_norm(X)\n",
    "        logits = self.out_head(X)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformeBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 1 : Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 2 : Create an instance of DummyGPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyGPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): DummyTransformeBlock()\n",
      "    (1): DummyTransformeBlock()\n",
      "    (2): DummyTransformeBlock()\n",
      "    (3): DummyTransformeBlock()\n",
      "    (4): DummyTransformeBlock()\n",
      "    (5): DummyTransformeBlock()\n",
      "    (6): DummyTransformeBlock()\n",
      "    (7): DummyTransformeBlock()\n",
      "    (8): DummyTransformeBlock()\n",
      "    (9): DummyTransformeBlock()\n",
      "    (10): DummyTransformeBlock()\n",
      "    (11): DummyTransformeBlock()\n",
      "  )\n",
      "  (final_norm): DummyLayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape : torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
      "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
      "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
      "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
      "\n",
      "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
      "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
      "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
      "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"output shape :\",logits.shape)\n",
    "print(logits) # 2 rows corresponding to the 2 text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT Architecture Part 2 : Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5) # 2 batches , 5 inputs\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU()) # 5 inputs, 6 outputs\n",
    "out = layer(batch_example)\n",
    "print(out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: \n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "\n",
      "Variance: \n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Mean, Var for each batch\n",
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean: \\n\", mean)\n",
    "print(\"\\nVariance: \\n\",var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer output:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean: \n",
      " tensor([[9.9341e-09],\n",
      "        [0.0000e+00]], grad_fn=<MeanBackward1>)\n",
      "Variance: \n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Apply layer Normalization\n",
    "\n",
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Normalized layer output:\\n\", out_norm)\n",
    "print(\"Mean: \\n\", mean)\n",
    "print(\"Variance: \\n\",var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: \n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance: \n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean: \\n\", mean)\n",
    "print(\"Variance: \\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5 # small value to avoid zero division\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: \n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance: \n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, keepdim=True, unbiased=False)\n",
    "print(\"Mean: \\n\", mean)\n",
    "print(\"Variance: \\n\",var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT Architecture Part 3 : FeedForward NN With GELU Actization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3)) \n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# some sample data\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], ['GELU', 'RELU']), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f'{label} activation function')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel(f'{label}(x)')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'], 4 * cfg['emb_dim']), # increase output 4 times (Expansion)\n",
    "            GELU(),  # Activation \n",
    "            nn.Linear(4 * cfg['emb_dim'], cfg['emb_dim']) # Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n",
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = ffn(x)\n",
    "print(x.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT Architecture Part 4 : Shourtcut Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # compute the output of the current layer\n",
    "            layer_output = layer(x)\n",
    "            \n",
    "            # check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([1. , 0. , -1.])\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # Calculate loss based on how close the target and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "\n",
    "    # Backward pass to calculate the gradients \n",
    "    loss.backward()\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f'{name} has gradient mean of {param.grad.abs().mean().item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041653171182\n",
      "layers.3.0.weight has gradient mean of 0.001398873864673078\n",
      "layers.4.0.weight has gradient mean of 0.005049646366387606\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model=model_without_shortcut, x=sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732502937317\n",
      "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=True)\n",
    "\n",
    "# solve the vanishing gradient problem\n",
    "print_gradients(model=model_with_shortcut, x=sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT Architecture Part 5 : Coding Attention and Linear Layers in a Transformer\n",
    " - The building blocks : Layer Norm, GELU and Feed-Forward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 small config\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\" : 50257,\n",
    "    \"context_length\" : 1024,\n",
    "    \"emb_dim\" : 768,\n",
    "    \"n_heads\" : 12,\n",
    "    \"n_layers\" : 12,\n",
    "    \"drop_rate\" : 0.1,\n",
    "    \"qkv_bias\" : False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5 # small value to avoid zero division\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3)) \n",
    "        ))\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'], 4 * cfg['emb_dim']), # increase output 4 times (Expansion)\n",
    "            GELU(),  # Activation \n",
    "            nn.Linear(4 * cfg['emb_dim'], cfg['emb_dim']) # Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import MultiHeadAttention\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg['emb_dim'],\n",
    "            d_out=cfg['emb_dim'],\n",
    "            context_length=cfg['context_length'],\n",
    "            num_heads=cfg['n_heads'],\n",
    "            dropout=cfg['drop_rate'],\n",
    "            qkv_bias=cfg['qkv_bias']\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2 = LayerNorm(cfg['emb_dim'])\n",
    "        self.drop_shortcuts = nn.Dropout(cfg['drop_rate'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x) # shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcuts(x)\n",
    "        x = x + shortcut # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcuts(x)\n",
    "        x = x + shortcut # Add the original input back\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print('Input shape:', x.shape)\n",
    "print('Output shape:', output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT Architecture Part 6 : Entire GPT Model Architecture Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 small config\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\" : 50257,\n",
    "    \"context_length\" : 1024,\n",
    "    \"emb_dim\" : 768,\n",
    "    \"n_heads\" : 12,\n",
    "    \"n_layers\" : 12,\n",
    "    \"drop_rate\" : 0.1,\n",
    "    \"qkv_bias\" : False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from modules import MultiHeadAttention\n",
    "\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        # Use a placeholder for LayerNorm\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformeBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "\n",
    "        self.final_norm = DummyLayerNorm(cfg['emb_dim'])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg['emb_dim'], cfg['vocab_size'], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "\n",
    "        X = tok_embeds + pos_embeds\n",
    "        X = self.drop_emb(X)\n",
    "        X = self.trf_blocks(X) # transformer blocks\n",
    "        X = self.final_norm(X)\n",
    "        logits = self.out_head(X)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformeBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5 # small value to avoid zero division\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3)) \n",
    "        ))\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'], 4 * cfg['emb_dim']), # increase output 4 times (Expansion)\n",
    "            GELU(),  # Activation \n",
    "            nn.Linear(4 * cfg['emb_dim'], cfg['emb_dim']) # Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg['emb_dim'],\n",
    "            d_out=cfg['emb_dim'],\n",
    "            context_length=cfg['context_length'],\n",
    "            num_heads=cfg['n_heads'],\n",
    "            dropout=cfg['drop_rate'],\n",
    "            qkv_bias=cfg['qkv_bias']\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2 = LayerNorm(cfg['emb_dim'])\n",
    "        self.drop_shortcuts = nn.Dropout(cfg['drop_rate'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x) # shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcuts(x)\n",
    "        x = x + shortcut # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcuts(x)\n",
    "        x = x + shortcut # Add the original input back\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we gonna use all these classes to code the entire GPT Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
    "        self.drop_emb = nn.Dropout(cfg['drop_rate'])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        ) # 12 trf block\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg['emb_dim'])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg['emb_dim'], cfg['vocab_size'], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape # seq_len = num tokens\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds # shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
      "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
      "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
      "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
      "\n",
      "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
      "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
      "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
      "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x0000021658DAAF80>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of params: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total number of params: {total_params:,}') # 163M params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print('Token embedding layer shape:', model.tok_emb.weight.shape)\n",
    "print('Output layer shape:', model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of trainable params: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gp2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f'Total of trainable params: {total_params_gp2:,}') # 124M params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024*1024)\n",
    "print(f'Total size of the model: {total_size_mb:.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT Architecture Part 7 : Generating Text From Output Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # Eg if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the best 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) #[batch, n_tokens , vocab_size]\n",
    "\n",
    "        # Focus only on the last time step (last token)\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # Apply softma to get probabilities\n",
    "        probas= torch.softmax(logits, dim=-1) # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True) # (btch, 1)\n",
    "\n",
    "        # Append smapled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1) # (btch, n_token+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716, 257, 220]\n",
      "encoded_tensor shape:  torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am a \"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print('encoded_tensor shape: ',encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  tensor([[15496,    11,   314,   716,   257,   220, 30387, 13585, 25265, 40975,\n",
      "           588, 34845]])\n",
      "Output length:  12\n"
     ]
    }
   ],
   "source": [
    "# we disable dropout since we are not training the model\n",
    "\n",
    "model.eval() #disables random components like dropout\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "print(\"Output: \",out)\n",
    "print(\"Output length: \", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am a Spring Facfashion combating like wrestler\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text) # we are not train the model yet\n",
    "# we just implemented the GPT Architecture and initilized it with initial random weights\n",
    "# we need then to train this 124M params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval(); # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you Aeiman Byeswickattributeometer inspector Normandy freezerigrate\n"
     ]
    }
   ],
   "source": [
    "# we reduce the context length of only 256 tokens, GPT-2 model used 1024 tokens\n",
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "\n",
    "print('Output text:\\n', token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Calculating the text generation loss : cross-entropy and perplexity\n",
    "- we measure what good text is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([\n",
    "    [16833, 3626, 6100], # Every effort moves\n",
    "    [40,     1107, 588]  # I really like\n",
    "])\n",
    "\n",
    "targets = torch.tensor([\n",
    "    [3626, 6100, 345], # effort moves you\n",
    "    [1107, 588, 11311] # really like chocolate\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "torch.Size([2, 3, 50257])\n",
      "tensor([[[    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
      "              0.0000,     0.0000],\n",
      "         [    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
      "              0.0000,     0.0000],\n",
      "         [    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
      "              0.0000,     0.0000]],\n",
      "\n",
      "        [[    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
      "              0.0000,     0.0000],\n",
      "         [    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
      "              0.0000,     0.0000],\n",
      "         [    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
      "              0.0000,     0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "print(logits.shape)\n",
    "probas = torch.softmax(logits, dim=-1) # proba of each token in vcb\n",
    "print(probas.shape) # [batch_size, num_tokens, vocab_size]\n",
    "print(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[36397],\n",
      "         [39619],\n",
      "         [20610]],\n",
      "\n",
      "        [[ 8615],\n",
      "         [49289],\n",
      "         [47105]]])\n"
     ]
    }
   ],
   "source": [
    "# The index of max value for each column\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 2:  Gathering SerbianFriday\n"
     ]
    }
   ],
   "source": [
    "# target = y_true , output = y_pred\n",
    "print(f'Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}')\n",
    "print(f'Outputs batch 2: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}') # random output\n",
    "# the result : target =! output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([    0.0000,     0.0000,     0.0000])\n",
      "Text 2: tensor([    0.0000,     0.0000,     0.0000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print('Text 1:', target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print('Text 2:', target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.6600, -10.7936, -11.3531, -10.0591, -11.0276, -11.3658])\n"
     ]
    }
   ],
   "source": [
    "# Merge and Compute logarithm of all token probas\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.8765)\n"
     ]
    }
   ],
   "source": [
    "# Claculate the average proba for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8765)\n"
     ]
    }
   ],
   "source": [
    "# Claculate the negative average proba for each token\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape [batch_size, num_tokens, vocab_size]\n",
    "print('Logits shape:', logits.shape)\n",
    "\n",
    "# Targets have shape [batch_size, num_tokens]\n",
    "print('Targets shape:', targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattend logits: torch.Size([6, 50257])\n",
      "Flattend targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattend logits:\", logits_flat.shape)\n",
    "print(\"Flattend targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8765)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(52918.7773)\n"
     ]
    }
   ],
   "source": [
    "# A concept related to the cross-entropy loss is the perplexity of an LLM (perp = exp(cross-entropy loss))\n",
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20479\n",
      "I HAD always thought Jack Gisburn rather a cheap \n"
     ]
    }
   ],
   "source": [
    "with open('the-verdict.txt', mode='r') as f:\n",
    "    text_data = f.read()\n",
    "\n",
    "print(len(text_data))\n",
    "print(text_data[:49]) # first 50 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters:  20479\n",
      "Tokens:  5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print('Characters: ', total_characters)\n",
    "print('Tokens: ', total_tokens)\n",
    "\n",
    "# Lec27 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
