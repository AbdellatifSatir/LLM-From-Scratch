{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning For Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f'{data_file_path} already exists. Skipping download and extraction')\n",
    "        return\n",
    "\n",
    "    # Create an unverified SSL context\n",
    "    ssl_context = ssl._create_unverified_context()\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file exeptension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f'File downloaded and saved as {data_file_path}')\n",
    "\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    ham = df[df[\"Label\"] == \"ham\"]\n",
    "    spam = df[df[\"Label\"] == \"spam\"]\n",
    "\n",
    "    ham = ham.sample(n=len(spam), random_state=42)\n",
    "\n",
    "    return pd.concat([ham, spam]).reset_index(drop=True)\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>If i not meeting 端 all rite then i'll go home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>I.ll always be there, even if its just in spir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry that took so long, omw now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>I thk 50 shd be ok he said plus minus 10.. Did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Dunno i juz askin cos i got a card got 20% off...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text\n",
       "0   ham  If i not meeting 端 all rite then i'll go home ...\n",
       "1   ham  I.ll always be there, even if its just in spir...\n",
       "2   ham                   Sorry that took so long, omw now\n",
       "3   ham  I thk 50 shd be ok he said plus minus 10.. Did...\n",
       "4   ham  Dunno i juz askin cos i got a card got 20% off..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>If i not meeting 端 all rite then i'll go home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I.ll always be there, even if its just in spir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Sorry that took so long, omw now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I thk 50 shd be ok he said plus minus 10.. Did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Dunno i juz askin cos i got a card got 20% off...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                               Text\n",
       "0      0  If i not meeting 端 all rite then i'll go home ...\n",
       "1      0  I.ll always be there, even if its just in spir...\n",
       "2      0                   Sorry that took so long, omw now\n",
       "3      0  I thk 50 shd be ok he said plus minus 10.. Did...\n",
       "4      0  Dunno i juz askin cos i got a card got 20% off..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "balanced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% train, 10% validation, 20% test\n",
    "\n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire dataframe\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(train_frac * len(df))\n",
    "    validation_end = int(validation_frac * len(df)) + train_end\n",
    "\n",
    "    # Split the Shuffled data\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end : validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_end : 1045\n",
      "validation_end : 1194\n"
     ]
    }
   ],
   "source": [
    "train_end = int(0.7 * len(balanced_df))\n",
    "validation_end = int(0.1 * len(balanced_df)) + train_end\n",
    "\n",
    "print(\"train_end :\",train_end) \n",
    "print(\"validation_end :\",validation_end )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1045, 149, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(validation_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv(r\"sms_spam_collection\\train.csv\", index=None)\n",
    "# validation_df.to_csv(r\"sms_spam_collection\\validation.csv\", index=None)\n",
    "# test_df.to_csv(r\"sms_spam_collection\\test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Prepare data into input-target pairs\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenized texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data['Text']\n",
    "            ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length] for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "        \n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text)) for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index]['Label']\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "train_dataset = SpamDataset(\n",
    "    csv_file=r\"sms_spam_collection\\train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length) # since the longest seq in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=r\"sms_spam_collection\\validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=r\"sms_spam_collection\\test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "\n",
    "print(val_dataset.max_length) \n",
    "print(test_dataset.max_length) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the datasets as inputs, we can instantiate the data loaders\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True # if the last batch has a smaller data \n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dim: torch.Size([8, 120])\n",
      "Label batch dim: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print('Input batch dim:', input_batch.shape)\n",
    "print('Label batch dim:', target_batch.shape)\n",
    "# every input batch has 8 rows and 120 cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(train_loader)} training batches') # df_train.shape[0]/8\n",
    "print(f'{len(val_loader)} validation batches')\n",
    "print(f'{len(test_loader)} test batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130.625\n",
      "18.625\n",
      "37.5\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape[0]/8)\n",
    "print(validation_df.shape[0]/8)\n",
    "print(test_df.shape[0]/8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Initializing a Model With Pre-Trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    'vocab_size': 50257,\n",
    "    'context_length': 1024,\n",
    "    'drop_rate': 0.0,\n",
    "    'qkv_bias': True,\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25}\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG['context_length'], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context\"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize the dataset with\"\n",
    "    f\"`max_length = {BASE_CONFIG['context_length']}`\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shapes mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params['blocks'][b]['attn']['c_attn'])['w'], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "        \n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params['blocks'][b]['attn']['c_attn'])['b'], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "        \n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params['blocks'][b]['attn']['c_proj']['w'].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params['blocks'][b]['attn']['c_proj']['b'])\n",
    "        \n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params['blocks'][b]['mlp']['c_fc']['w'].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params['blocks'][b]['mlp']['c_fc']['b'])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params['blocks'][b]['mlp']['c_proj']['w'].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params['blocks'][b]['mlp']['c_proj']['b'])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params['blocks'][b]['ln_1']['g'])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params['blocks'][b]['ln_1']['b'])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params['blocks'][b]['ln_2']['g'])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params['blocks'][b]['ln_2']['b'])\n",
    "        \n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params['g'])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params['b'])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params['wte'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt2-small (124M)'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHOOSE_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip('(').rstrip(')')\n",
    "\n",
    "from gpt_download3 import download_and_load_gpt2\n",
    "from modules import GPTModel\n",
    "\n",
    "settings, params = download_and_load_gpt2(model_size, models_dir='gpt2')\n",
    "\n",
    "# Update BASE_CONFIG with the correct vocabulary size\n",
    "BASE_CONFIG['vocab_size'] = settings['n_vocab']\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test text generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "# the model loaded correctly, lets test it\n",
    "from modules import text_to_token_ids, token_ids_to_text, generate_text_simple\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG['context_length'],\n",
    ")\n",
    "\n",
    "print('Output text:\\n', token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "# the model loaded correctly, lets test it\n",
    "from modules import text_to_token_ids, token_ids_to_text, generate_text_simple\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG['context_length'],\n",
    ")\n",
    "\n",
    "print('Output text:\\n', token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finetune with our spam dataset (Finetune as a spam classifier)\n",
    "-\n",
    "- But before that, lets see if the model can perhaps already classify spam messages by prompting it with instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Is the following text 'spam' Answer with 'yes' or 'no':  'You are a winner you have been specially selected to receive $1000 cash or $2000 award.'  'You have been specially selected to receive $1000 cash or $2000 award\n"
     ]
    }
   ],
   "source": [
    "# lets see if the model can perhaps already classify spam messages by prompting it with instructions\n",
    "\n",
    "text_2 = (\n",
    "    \"Is the following text 'spam' Answer with 'yes' or 'no': \"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or $2000 award.' \"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG['context_length'],\n",
    ")\n",
    "\n",
    "print('Output text:\\n', token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Adding a Classification Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will Finetune :\n",
    "    - Final Output Head\n",
    "    - Final Transformer Block\n",
    "    - Final Layer Norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the output shape for instead of predict the dim of the next word, we will do the same thing but the output dim will change the model will classify (just two output yes/no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcuts): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcuts): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcuts): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcuts): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcuts): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcuts): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcuts): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcuts): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcuts): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcuts): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcuts): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcuts): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# we observe that the model contains 12 transformer blocks, each with a multi-head self-attention mechanism and a feedforward neural network. The model also has a final layer normalization and a linear output head.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We replace the output head (out_head) with a new output layer that has two output units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first freeze the model, meaning that we make all layers non-trainable\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps 50257 to num_classes=2 (spam or ham)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG['emb_dim'], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now train the model\n",
    "\n",
    "for params in model.trf_blocks[-1].parameters():\n",
    "    params.requires_grad = True\n",
    "\n",
    "for params in model.final_norm.parameters():\n",
    "    params.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dim: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dim:\", model(inputs).shape) #  (batch_size, num_toknes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dim: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dim:\", outputs.shape) # (batch_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "# we will focus on the last row corresponding to the last token in the input sequence (its contains all the infos about the other tokens)\n",
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating The Classification Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n",
      "tensor([[5.0598e-04, 9.9949e-01]])\n",
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])\n",
    "\n",
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "print(probas)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "# Or\n",
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    num_examples = 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.4625\n",
      "Validation accuracy: 0.45\n",
      "Test accuracy: 0.4875\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy}\")\n",
    "print(f\"Validation accuracy: {val_accuracy}\")\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as before \n",
    "# compute loss for a user specified number of batches\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data \n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 13.655\n",
      "Validation loss: 13.835\n",
      "Test loss: 13.381\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning The Model On Supervised Data\n",
    "- The Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the loss over the training and validation set while ensuring the model is in evaluation mode with gradient tracking \n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval() # dropout disable\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall the as 'train_model_simple' in prev chapter\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter):\n",
    "\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    examples_seen = 0\n",
    "    global_step = -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss grads\n",
    "            examples_seen += input_batch.shape[0] # New : track examples instead of toknes\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f'Ep {epoch+1} (Step {global_step:06d}): '\n",
    "                      f'Train loss {train_loss:.3f}, Val loss {val_loss:.3f}')\n",
    "                \n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}%\", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "    \n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.160, Val loss 2.374\n",
      "Ep 1 (Step 000050): Train loss 0.654, Val loss 0.631\n",
      "Ep 1 (Step 000100): Train loss 0.531, Val loss 0.566\n",
      "Training accuracy: 85.00%Validation accuracy: 75.00%\n",
      "Ep 2 (Step 000150): Train loss 0.572, Val loss 0.513\n",
      "Ep 2 (Step 000200): Train loss 0.283, Val loss 0.387\n",
      "Ep 2 (Step 000250): Train loss 0.548, Val loss 0.334\n",
      "Training accuracy: 87.50%Validation accuracy: 72.50%\n",
      "Ep 3 (Step 000300): Train loss 0.312, Val loss 0.323\n",
      "Ep 3 (Step 000350): Train loss 0.371, Val loss 0.241\n",
      "Training accuracy: 90.00%Validation accuracy: 92.50%\n",
      "Ep 4 (Step 000400): Train loss 0.115, Val loss 0.201\n",
      "Ep 4 (Step 000450): Train loss 0.034, Val loss 0.108\n",
      "Ep 4 (Step 000500): Train loss 0.409, Val loss 0.065\n",
      "Training accuracy: 97.50%Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.201, Val loss 0.052\n",
      "Ep 5 (Step 000600): Train loss 0.071, Val loss 0.055\n",
      "Training accuracy: 100.00%Validation accuracy: 97.50%\n",
      "Training completed in 53.61 minutes\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5 \n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device, num_epochs=num_epochs, eval_freq=50, eval_iter=5\n",
    ")\n",
    " \n",
    "# every after each batches printing the training and validation loss\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f'Training completed in {execution_time_minutes:.2f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, label=f\"Validation {label}\", linestyle='-.')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend(label.capitalize())\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny() # 2nd x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0) # invivible plot\n",
    "    ax2.set_xlabel('Examples seen')\n",
    "\n",
    "    fig.tight_layout() # Adjust layout to make soom\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_10008\\379311099.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(\"review_classifier.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the LLM as A Spam Classifier\n",
    "- Use the model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad seq to the longest seq\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model infzrence\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :] # Logits of the output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight. Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
