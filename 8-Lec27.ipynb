{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 small config\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\" : 50257,\n",
    "    \"context_length\" : 256, #1024,\n",
    "    \"emb_dim\" : 768,\n",
    "    \"n_heads\" : 12,\n",
    "    \"n_layers\" : 12,\n",
    "    \"drop_rate\" : 0.1,\n",
    "    \"qkv_bias\" : False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20479\n",
      "I HAD always thought Jack Gisburn rather a cheap \n"
     ]
    }
   ],
   "source": [
    "with open('the-verdict.txt', mode='r') as f:\n",
    "    text_data = f.read()\n",
    "\n",
    "print(len(text_data))\n",
    "print(text_data[:49]) # first 50 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters:  20479\n",
      "Tokens:  5145\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print('Characters: ', total_characters)\n",
    "print('Tokens: ', total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implementing the DataLoader (divide the dataset into training and validation sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18431\n",
      "18431\n",
      "2048\n"
     ]
    }
   ],
   "source": [
    "from modules import GPTDatasetV1, create_dataloader_v1\n",
    "\n",
    "\n",
    "# Trian/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "print(split_idx)\n",
    "print(len(train_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Trian/validation sets\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    txt=train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=True,\n",
    "    shuflle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    txt=val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=False,\n",
    "    shuflle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader)) # 9 batches\n",
    "print(len(val_loader)) # 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514.4999999999999\n",
      "4630.5\n"
     ]
    }
   ],
   "source": [
    "print(total_tokens * (1-train_ratio))\n",
    "print(total_tokens * (train_ratio))\n",
    "\n",
    "# Sanity check\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M['context_length']:\n",
    "    print('Not enough tokens for the training loader.'\n",
    "          \"Try to lower the 'GPT_CONFIG_124M context_length' or increase the training_ratio \")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M['context_length']:\n",
    "    print('Not enough tokens for the validation loader.'\n",
    "          \"Try to lower the 'GPT_CONFIG_124M context_length' or decrease the validation_ratio \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "9\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\Desktop\\LLM from scratch\\modules.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.input_ids[idx]) , torch.tensor(self.target_ids[idx])\n"
     ]
    }
   ],
   "source": [
    "# check if the data was loaded correctly\n",
    "\n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))\n",
    "# Train : input-target pairs [2 samples, 256 tokens]\n",
    "# Validation : input-target pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "# An optional check that the data was loaded correctly\n",
    "\n",
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print('Training tokens:', train_tokens)\n",
    "print('Validation tokens:', val_tokens)\n",
    "print(\"All tokens:\", train_tokens+val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import GPTModel\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval(); # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cross-entropy loss of a given batch\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "# compute loss for a user specified number of batches\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data \n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have a machine with a CUDA supported GPU, the LLM will train on the GPU without making any changes\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device); # no assignment model = model.to(device) necessary for nn.Module classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758347829183\n",
      "Validation loss: 10.981106758117676\n",
      "CPU times: total: 42.8 s\n",
      "Wall time: 23.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can apply the same code on different dataset with different context_length (generizable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop For The LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the loss over the training and validation set while ensuring the model is in evaluation mode with gradient tracking \n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval() # dropout disable\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tiktoken\n",
    "# from modules import text_to_token_ids, generate_text_simple, token_ids_to_text \n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # Eg if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the best 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) #[batch, n_tokens , vocab_size]\n",
    "\n",
    "        # Focus only on the last time step (last token)\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # Apply softma to get probabilities\n",
    "        probas= torch.softmax(logits, dim=-1) # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True) # (btch, 1)\n",
    "\n",
    "        # Append smapled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1) # (btch, n_token+1)\n",
    "\n",
    "    return idx\n",
    "\n",
    "\n",
    "# convenience func thet we use to track whether th model improves during the training, its takes a text snippet (strat_context) as input, converts it into token IDs and feeds it to the LLM to generate a text\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded, max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace('\\n', ' ')) # Compact print format\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 256,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': False}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    track_tokens_seen = []\n",
    "    tokens_seen = 0\n",
    "    global_step = -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss grads\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in \n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f'Ep {epoch+1} (Step {global_step:06d}): '\n",
    "                      f'Train loss {train_loss:.3f}, Val loss {val_loss:.3f}')\n",
    "                \n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    \n",
    "    return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\Desktop\\LLM from scratch\\modules.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.input_ids[idx]) , torch.tensor(self.target_ids[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.783, Val loss 9.927\n",
      "Ep 1 (Step 000005): Train loss 7.985, Val loss 8.335\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.753, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 6.114, Val loss 6.573\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,,,,, and,,,, and,, and,,,,, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.525, Val loss 6.490\n",
      "Ep 3 (Step 000025): Train loss 5.324, Val loss 6.387\n",
      "Every effort moves you, and to the picture.                      \"I, and the of the of the's the honour, and, and I had been, and I\n",
      "Ep 4 (Step 000030): Train loss 4.761, Val loss 6.360\n",
      "Ep 4 (Step 000035): Train loss 4.461, Val loss 6.258\n",
      "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 3.833, Val loss 6.196\n",
      "Every effort moves you know the \"Oh, and he was not the fact by his last word.         \"I was.      \"Oh, I felt a little a little the    \n",
      "Ep 6 (Step 000045): Train loss 3.352, Val loss 6.139\n",
      "Ep 6 (Step 000050): Train loss 2.861, Val loss 6.112\n",
      "Every effort moves you know; and my dear, and he was not the fact with a little of the house of the fact of the fact, and.                       \n",
      "Ep 7 (Step 000055): Train loss 2.347, Val loss 6.138\n",
      "Ep 7 (Step 000060): Train loss 2.084, Val loss 6.179\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I looked--as of the fact, and I felt him--his back his head to the donkey. \"Oh, and_--because he had always _\n",
      "Ep 8 (Step 000065): Train loss 1.521, Val loss 6.176\n",
      "Ep 8 (Step 000070): Train loss 1.272, Val loss 6.178\n",
      "Every effort moves you?\" \"I didn't bear the picture--I told me.  \"I looked up, and went on groping and Mrs. I was back the head to look up at the honour being _mine_--because he was when I\n",
      "Ep 9 (Step 000075): Train loss 1.000, Val loss 6.277\n",
      "Ep 9 (Step 000080): Train loss 0.718, Val loss 6.281\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.506, Val loss 6.325\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to the donkey again. I saw that, and down the room, when I\n",
      "Training completed in 21.42 minutes\n"
     ]
    }
   ],
   "source": [
    "# Test with 10 epochs\n",
    "import time \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10 \n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq=5, eval_iter=5, start_context='Every effort moves you', tokenizer=tokenizer\n",
    ")\n",
    "# every after each batches printing the training and validation loss\n",
    "# huge number of params +120M\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f'Training completed in {execution_time_minutes:.2f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ValueError: too many values to unpack (expected 2)\n",
    "# <!-- error at the end of training 10th epoch -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see, based on the results printed during the training, the training loss improves drastically, strarting with a value of 9.783 and and converging to 0.506\n",
    "\n",
    "# Similatr to the training loss, we can see that the validation loss starts high (9.927) and decreases during the training. However, it never bocomes as small as the training set loss and remains at 6.325 after the A0th epoch.\n",
    "\n",
    "# validation loss > training loss : indicate that the model is overfitting to the training data (cuz of the very small data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\Desktop\\LLM from scratch\\modules.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.input_ids[idx]) , torch.tensor(self.target_ids[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.783, Val loss 9.927\n",
      "Ep 1 (Step 000005): Train loss 7.985, Val loss 8.335\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.753, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 6.114, Val loss 6.573\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,,,,, and,,,, and,, and,,,,, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.525, Val loss 6.490\n",
      "Ep 3 (Step 000025): Train loss 5.324, Val loss 6.387\n",
      "Every effort moves you, and to the picture.                      \"I, and the of the of the's the honour, and, and I had been, and I\n",
      "Ep 4 (Step 000030): Train loss 4.761, Val loss 6.360\n",
      "Ep 4 (Step 000035): Train loss 4.461, Val loss 6.258\n",
      "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 3.833, Val loss 6.196\n",
      "Every effort moves you know the \"Oh, and he was not the fact by his last word.         \"I was.      \"Oh, I felt a little a little the    \n",
      "Training completed in 11.53 minutes\n"
     ]
    }
   ],
   "source": [
    "# # Another test with just 5 epochs\n",
    "# import time \n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# torch.manual_seed(123)\n",
    "# model = GPTModel(GPT_CONFIG_124M)\n",
    "# model.to(device)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "# num_epochs = 5 \n",
    "# train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "#     model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq=5, eval_iter=5, start_context='Every effort moves you', tokenizer=tokenizer\n",
    "# )\n",
    "# # every after each batches printing the training and validation loss\n",
    "# # huge number of params +120M\n",
    "# end_time = time.time()\n",
    "# execution_time_minutes = (end_time - start_time) / 60\n",
    "# print(f'Training completed in {execution_time_minutes:.2f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([9.782992172241212,\n",
       "  7.98503303527832,\n",
       "  6.7534150123596195,\n",
       "  6.113782119750977,\n",
       "  5.524630165100097,\n",
       "  5.3239333152771,\n",
       "  4.761361694335937,\n",
       "  4.460933542251587,\n",
       "  3.8325411796569826,\n",
       "  3.3516302585601805,\n",
       "  2.861086368560791,\n",
       "  2.347222995758057,\n",
       "  2.0840754747390746,\n",
       "  1.5214445829391479,\n",
       "  1.2722728729248047,\n",
       "  0.9998903870582581,\n",
       "  0.7182631373405457,\n",
       "  0.5058149099349976],\n",
       " [9.926935195922852,\n",
       "  8.334564208984375,\n",
       "  7.047619342803955,\n",
       "  6.5733208656311035,\n",
       "  6.489957332611084,\n",
       "  6.387439250946045,\n",
       "  6.3603034019470215,\n",
       "  6.2576141357421875,\n",
       "  6.196468353271484,\n",
       "  6.139320373535156,\n",
       "  6.111726760864258,\n",
       "  6.137843132019043,\n",
       "  6.179319381713867,\n",
       "  6.175858497619629,\n",
       "  6.1776227951049805,\n",
       "  6.276617527008057,\n",
       "  6.280826091766357,\n",
       "  6.325016498565674],\n",
       " [512,\n",
       "  3072,\n",
       "  5632,\n",
       "  8192,\n",
       "  10752,\n",
       "  13312,\n",
       "  15872,\n",
       "  18432,\n",
       "  20992,\n",
       "  23552,\n",
       "  26112,\n",
       "  28672,\n",
       "  31232,\n",
       "  33792,\n",
       "  36352,\n",
       "  38912,\n",
       "  41472,\n",
       "  44032])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses, val_losses, tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, label=\"Validation loss\", linestyle='-.')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    # only show integer labels\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True)) \n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny() # 2nd x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0) # invivible plot\n",
    "    ax2.set_xlabel('Tokens seen')\n",
    "\n",
    "    fig.tight_layout() # Adjust layout to make soom\n",
    "    plt.savefig('loss-plot.pdf')\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decodings Strategies To Control Randomness\n",
    "- make sure that the model does not overffit too mush (make sure that the model predict new words not only memorize the training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids('Every effort moves you', tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "print('Output text:\\n', token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decodings Strategy 1: Temperature Scaling\n",
    "- Previously, inside generate_text_simple(), we always sampled the token with the highest proba as the next token using torch.argmax, also known as greedy decoding.\n",
    "- To generate text with more variety we can replace the argmax with a function that samples from a proba distribution ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'closer',\n",
       " 1: 'every',\n",
       " 2: 'effort',\n",
       " 3: 'forward',\n",
       " 4: 'inches',\n",
       " 5: 'moves',\n",
       " 6: 'pizza',\n",
       " 7: 'toward',\n",
       " 8: 'you'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example with small vocab\n",
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v:k for k,v in vocab.items()}\n",
    "inverse_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
      "        1.0120e-04, 3.5758e-01, 4.0122e-03])\n",
      "3\n",
      "forward\n"
     ]
    }
   ],
   "source": [
    "# Assume the LLM is given the start context \"every effort moves you\" and generate the following new logits tensor\n",
    "\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ") # n_cols = vocab_size\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "print(probas)\n",
    "\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(next_token_id)\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to implement a probabilistic sampling process, we can now replace the argmax with the multinomial function in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
      "        1.0120e-04, 3.5758e-01, 4.0122e-03])\n",
      "7\n",
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "print(probas)\n",
    "\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(next_token_id)\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sammpled_ids = torch.bincount( torch.tensor(sample))\n",
    "    for i, freq in enumerate(sammpled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\") # how many times each token chosen\n",
    "\n",
    "print_sampled_tokens(probas=probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
      "        1.0120e-04, 3.5758e-01, 4.0122e-03]), tensor([1.8530e-10, 3.5189e-26, 2.6890e-38, 9.9099e-01, 5.7569e-23, 4.4220e-37,\n",
      "        2.9718e-38, 9.0133e-03, 2.8514e-22]), tensor([0.1546, 0.0750, 0.0429, 0.2421, 0.0869, 0.0454, 0.0430, 0.2203, 0.0898])]\n"
     ]
    }
   ],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5] # original, higher confidence and lower confedence\n",
    "\n",
    "# calculate scaled probas\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "print(scaled_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ploting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_xlabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decodings Strategy 2: Top-k Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Restrict the sampled tokens to the top-k most likely tokens and exclude all other tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.5100,  0.8900, -1.9000,  6.7500,  1.6300, -1.6200, -1.8900,  6.2800,\n",
      "         1.7900])\n"
     ]
    }
   ],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "print(next_token_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print('Top logits:', top_logits)\n",
    "print('Top positions:', top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5100)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_logits[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "# Replace all the other values which does not belong the top 3 with - inf\n",
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Temperature Scaling and Top-k Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    # get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # filter logits with tok_k sampling\n",
    "        if top_k is not None:\n",
    "            # keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "\n",
    "        # apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # apply softmax to get probas\n",
    "            probs = torch.softmax(logits, dim=-1) # (batch size, context len)\n",
    "\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (batch_size, 1)\n",
    "        \n",
    "        # otherwise get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "\n",
    "        if idx_next == eos_id:\n",
    "            break # stop generating early if end-of-seq token is encountered\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1) # (batch_size, num_tokens+1)\n",
    "    \n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to my surprise, a little it was the\n",
      "\"Ah enough\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# token_ids = generate_text_simple(\n",
    "#     model=model,\n",
    "#     idx=text_to_token_ids('Every effort moves you', tokenizer),\n",
    "#     max_new_tokens=25,\n",
    "#     context_size=GPT_CONFIG_124M['context_length']\n",
    "# )\n",
    "# print('Output text:\\n', token_ids_to_text(token_ids, tokenizer))\n",
    "\n",
    "# Output text:\n",
    "#  Every effort moves you?\"\n",
    "\n",
    "# \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
    "\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids('Every effort moves you', tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M['context_length'],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print('Output text:\\n', token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to my surprise, a little it was the\n",
      "\"Ah enough\n"
     ]
    }
   ],
   "source": [
    "print('Output text:\\n', token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Saving Model Weights in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_4592\\1001060035.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcuts): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Saving optimizer state is also recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_stat_dict\": optimizer.state_dict()},\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_4592\\4161416692.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"model_and_optimizer.pth\")\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_stat_dict'])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Pre-Trained weights from OpenAI\n",
    "- Download the weights from [kaggle](https://www.kaggle.com/datasets/xhlulu/openai-gpt2-weights)\n",
    "- Or use gpt_download3.py code file: [gpt_download3.py](https://drive.google.com/file/d/1JX_DNJ9Xvty_ItciHhl_3TyOfahkGvvI/view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import tqdm\n",
    "# import numpy as np\n",
    "\n",
    "# print(\"NumPy version: \", np.__version__)\n",
    "# print('TensorFlow version:', tf.__version__)\n",
    "# print('tqdm version:', tqdm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hepls us download the 7 files from gpt2 124M\n",
    "# from gpt_download3 import download_and_load_gpt2\n",
    "# import tensorflow as tf\n",
    "# import tqdm\n",
    "# import numpy as np\n",
    "\n",
    "# settings, params = download_and_load_gpt2(model_size='124M', models_dir='gpt2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 256,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': False}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
